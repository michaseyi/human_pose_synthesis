{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import PoseFlowModel\n",
    "from train import Trainer\n",
    "from utils.dataset_gen import generate_dataset\n",
    "from viewer.viewer import Viewer\n",
    "from viewer.amc_parser import parse_asf\n",
    "from utils.parser import parse_motion_file\n",
    "from utils.preprocessing import downsample_motion, tensor_to_motion_frames, motion_frames_to_tensor\n",
    "from data import metadata, default_skeleton\n",
    "from utils.motion import Motion, MotionFrame\n",
    "from transforms3d.euler import euler2mat, mat2euler\n",
    "from copy import deepcopy\n",
    "from rotation_conversions import euler_angles_to_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 30, 93]), torch.Size([10, 30, 279]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x -> (B, L, 3)\n",
    "a = torch.randn(10, 30, 93)\n",
    "\n",
    "batch = a.shape[:-1]\n",
    "a = a.view(-1, 3)\n",
    "\n",
    "\n",
    "c = []\n",
    "for b in a:\n",
    "    c.append(euler_angles_to_matrix(b, 'XYZ').view(-1))\n",
    "\n",
    "c = torch.stack(c, dim=0)\n",
    "c = c.reshape(*batch, -1)\n",
    "a = a.reshape(*batch, -1)\n",
    "\n",
    "a.shape, c.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.7816e-08, -1.0000e+00,  6.5590e-08])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rotation = torch.tensor(euler2mat(*torch.tensor([180, -30, -90]).deg2rad().tolist())).to(torch.float32)\n",
    "v = torch.tensor([1, -4.48948e-011, -5.89033e-027]).to(torch.float32)\n",
    "global_rotation.inverse() @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bone in default_skeleton.bone_map.values():\n",
    "    if bone.name == 'root':\n",
    "        continue\n",
    "    global_rotation = torch.tensor(euler2mat(*torch.tensor(bone.axis).deg2rad().tolist())).to(torch.float32)\n",
    "    v = torch.tensor(bone.direction).to(torch.float32)\n",
    "    d = global_rotation.inverse() @ v\n",
    "    print(bone.name, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "block_size = 120\n",
    "frame_rate = 60\n",
    "dataset_path = \"dataset.bin\"\n",
    "checkpoint_path = \"checkpoint.pth\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_dataset('data/subjects/05', block_size, frame_rate, window_size=0).to(torch.float32)\n",
    "\n",
    "min = dataset[:, :, :3].min()\n",
    "max = dataset[:, :, :3].max()\n",
    "\n",
    "dataset[:, :, :3] = 2 * ((dataset[:, :, :3] - min) / (max - min)) - 1\n",
    "data = {\n",
    "    'dataset': dataset,\n",
    "    'min': min,\n",
    "    'max':max \n",
    "}\n",
    "torch.save(data, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoseFlowModel(block_size=block_size, pose_embd=216, block_embd=176, num_layers=12, num_heads=8, dropout=0.2, device=device).to(device)\n",
    "model.parameter_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, dataset_path, checkpoint_path, device=device, early_stopper_patience=30, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate_loss(trainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = parse_asf('data/subjects/02/02.asf')\n",
    "motion = parse_motion_file('data/subjects/02/02_02.amc')\n",
    "motion.frame_rate = metadata['5']['3'].frame_rate\n",
    "motion = downsample_motion(motion, frame_rate)\n",
    "motion_tensor = motion_frames_to_tensor(motion.frames)\n",
    "rotated_motion = rotate(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_motion = motion_tensor[50: 50 + block_size].clone().detach().to(device).to(torch.float32)\n",
    "\n",
    "start_motion = trainer.test_loader.dataset[10][0].to(device)\n",
    "\n",
    "model.eval()\n",
    "generated_motion = []\n",
    "with torch.no_grad():\n",
    "    for (pose, _) in zip(model.stream(start_motion.unsqueeze(0).to(device)), range(block_size )):\n",
    "        generated_motion.append(pose)\n",
    "generated_motion = torch.cat(generated_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleup(motion, min, max):\n",
    "    return motion\n",
    "    motion[:, :3] = (motion[:, :3] + 1) / 2\n",
    "    motion[:, :3] = motion[:, :3] * (max - min) + min\n",
    "    return motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_generated_frames = tensor_to_motion_frames(scaleup(torch.cat([start_motion.cpu(), generated_motion.cpu()], dim=0), trainer.data['min'], trainer.data['max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = Viewer(skeleton,  rotated_motion.frames)   \n",
    "view.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(motion: Motion) -> Motion:\n",
    "    rotated_motion = Motion(motion.frame_rate)\n",
    "    rotated_motion.frames = [rotate_motion_frame(frame, torch.tensor(90).deg2rad().item()) for frame in motion.frames]\n",
    "    return rotated_motion\n",
    "\n",
    "\n",
    "def rotate_motion_frame(motion_frame: MotionFrame, yaw: float) -> MotionFrame:\n",
    "    '''\n",
    "    Rotates a motion frame around the y axis\n",
    "    '''\n",
    "    rotated_motion_frame = deepcopy(motion_frame)\n",
    "    root = rotated_motion_frame['root']\n",
    "    position = torch.tensor(root[:3]).to(torch.float32)\n",
    "    rotation = torch.tensor(euler2mat(*torch.tensor(root[3:]).deg2rad().tolist())).to(torch.float32)\n",
    "\n",
    "    rotation_mat = torch.tensor(euler2mat(0, yaw, 0)).to(torch.float32)\n",
    "    position = rotation_mat @ position\n",
    "    rotation = rotation_mat @ rotation\n",
    "\n",
    "    rotated_motion_frame['root'] = position.tolist() + torch.tensor(mat2euler(rotation.numpy())).rad2deg().tolist()\n",
    "    return rotated_motion_frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
